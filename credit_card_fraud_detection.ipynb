{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Machine Learning Project\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements machine learning algorithms to detect fraudulent credit card transactions.\n",
    "\n",
    "### Dataset Information\n",
    "- **Features**: V1-V28 (PCA transformed), Time, Amount\n",
    "- **Target**: Class (0=Normal, 1=Fraud)\n",
    "- **Challenge**: Highly imbalanced dataset (~0.17% fraud cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "# Update the path to your actual file location\n",
    "data_path = r\"C:\\Users\\dasar\\OneDrive\\Desktop\\ds project\\major\\creditcard.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze class distribution\n",
    "class_counts = df['Class'].value_counts()\n",
    "class_percentages = df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(f\"Normal transactions (0): {class_counts[0]:,} ({class_percentages[0]:.2f}%)\")\n",
    "print(f\"Fraudulent transactions (1): {class_counts[1]:,} ({class_percentages[1]:.2f}%)\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "class_counts.plot(kind='bar', ax=ax1, color=['skyblue', 'salmon'])\n",
    "ax1.set_title('Class Distribution (Count)')\n",
    "ax1.set_xlabel('Class')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(class_counts.values, labels=['Normal', 'Fraud'], autopct='%1.2f%%', \n",
    "        colors=['skyblue', 'salmon'], startangle=90)\n",
    "ax2.set_title('Class Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze Time and Amount features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Time distribution\n",
    "axes[0,0].hist(df['Time'], bins=50, alpha=0.7, color='blue')\n",
    "axes[0,0].set_title('Distribution of Time')\n",
    "axes[0,0].set_xlabel('Time')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Amount distribution\n",
    "axes[0,1].hist(df['Amount'], bins=50, alpha=0.7, color='green')\n",
    "axes[0,1].set_title('Distribution of Amount')\n",
    "axes[0,1].set_xlabel('Amount')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Amount by class\n",
    "df[df['Class'] == 0]['Amount'].hist(bins=50, alpha=0.7, label='Normal', ax=axes[1,0])\n",
    "df[df['Class'] == 1]['Amount'].hist(bins=50, alpha=0.7, label='Fraud', ax=axes[1,0])\n",
    "axes[1,0].set_title('Amount Distribution by Class')\n",
    "axes[1,0].set_xlabel('Amount')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Box plot for Amount by Class\n",
    "df.boxplot(column='Amount', by='Class', ax=axes[1,1])\n",
    "axes[1,1].set_title('Amount Distribution by Class (Box Plot)')\n",
    "axes[1,1].set_xlabel('Class')\n",
    "axes[1,1].set_ylabel('Amount')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature scaling for Amount and Time\n",
    "scaler = RobustScaler()\n",
    "df['Amount_scaled'] = scaler.fit_transform(df[['Amount']])\n",
    "df['Time_scaled'] = scaler.fit_transform(df[['Time']])\n",
    "\n",
    "# Drop original Time and Amount columns\n",
    "df_processed = df.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "print(\"Data preprocessing completed!\")\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare features and target\n",
    "X = df_processed.drop('Class', axis=1)\n",
    "y = df_processed['Class']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Test set class distribution:\")\n",
    "print(y_test.value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Original training set shape: {X_train.shape}\")\n",
    "print(f\"SMOTE training set shape: {X_train_smote.shape}\")\n",
    "print(f\"\\nOriginal class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nSMOTE class distribution:\")\n",
    "print(pd.Series(y_train_smote).value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train and evaluate models on original imbalanced data\n",
    "print(\"=\" * 50)\n",
    "print(\"RESULTS ON ORIGINAL IMBALANCED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_original = {}\n",
    "for name, model in models.items():\n",
    "    results_original[name] = evaluate_model(model, X_train, X_test, y_train, y_test, name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train and evaluate models on SMOTE balanced data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RESULTS ON SMOTE BALANCED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_smote = {}\n",
    "for name, model in models.items():\n",
    "    results_smote[name] = evaluate_model(model, X_train_smote, X_test, y_train_smote, y_test, f\"{name} (SMOTE)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare models performance\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results_original.keys()) + [f\"{k} (SMOTE)\" for k in results_smote.keys()],\n",
    "    'Precision': [results_original[k]['precision'] for k in results_original.keys()] + \n",
    "                 [results_smote[k]['precision'] for k in results_smote.keys()],\n",
    "    'Recall': [results_original[k]['recall'] for k in results_original.keys()] + \n",
    "              [results_smote[k]['recall'] for k in results_smote.keys()],\n",
    "    'F1-Score': [results_original[k]['f1'] for k in results_original.keys()] + \n",
    "                [results_smote[k]['f1'] for k in results_smote.keys()],\n",
    "    'ROC-AUC': [results_original[k]['roc_auc'] for k in results_original.keys()] + \n",
    "               [results_smote[k]['roc_auc'] for k in results_smote.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.round(4))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original models\n",
    "for name, result in results_original.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {result['roc_auc']:.3f})\")\n",
    "\n",
    "# SMOTE models\n",
    "for name, result in results_smote.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
    "    plt.plot(fpr, tpr, linestyle='--', label=f\"{name} SMOTE (AUC = {result['roc_auc']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "1. **Class Imbalance**: The dataset is highly imbalanced with only ~0.17% fraud cases\n",
    "2. **SMOTE Impact**: SMOTE generally improves recall but may reduce precision\n",
    "3. **Model Performance**: Different models show varying performance on precision vs recall trade-off\n",
    "4. **Feature Importance**: Certain V features are more predictive of fraud\n",
    "\n",
    "### Recommendations:\n",
    "1. **For Production**: Choose model based on business cost of false positives vs false negatives\n",
    "2. **Threshold Tuning**: Adjust classification threshold based on business requirements\n",
    "3. **Ensemble Methods**: Consider combining multiple models for better performance\n",
    "4. **Real-time Monitoring**: Implement continuous model monitoring and retraining\n",
    "5. **Feature Engineering**: Explore additional features like transaction patterns, time-based features\n",
    "\n",
    "### Next Steps:\n",
    "- Hyperparameter tuning using GridSearchCV\n",
    "- Try advanced algorithms (XGBoost, Neural Networks)\n",
    "- Implement cost-sensitive learning\n",
    "- Deploy model using Flask/FastAPI\n",
    "- Set up model monitoring and alerting system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
